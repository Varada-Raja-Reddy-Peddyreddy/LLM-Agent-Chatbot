{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from secret_api_keys import Groq_API_Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initialize a chatGroq instance using the provided Groq API key and create an LLM object for interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000013C97C49A90>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000013C97C4A5D0>, model_name='llama3-groq-70b-8192-tool-use-preview', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(groq_api_key= Groq_API_Key,model_name  = \"llama3-groq-70b-8192-tool-use-preview\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm fine, thank you! How can I assist you today?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 17, 'total_tokens': 32, 'completion_time': 0.04546261, 'prompt_time': 0.004319219, 'queue_time': 0.029371556, 'total_time': 0.049781829}, 'model_name': 'llama3-groq-70b-8192-tool-use-preview', 'system_fingerprint': 'fp_ee4b521143', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd42604b-90e8-4a3c-8ce7-c9bcd4a62d21-0', usage_metadata={'input_tokens': 17, 'output_tokens': 15, 'total_tokens': 32})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hii,How are u ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define State of Chatbot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated # import the Annoted class for type hints with additional metadata\n",
    "from typing_extensions import TypedDict # import the TypeDict class for defining custom typed Dictionaries\n",
    "\n",
    "from langgraph.graph import StateGraph # import the StateGraph  class for create State Graph\n",
    "from langgraph.graph.message import add_messages # import the Add_message function for adding messages to list \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Typed Dictionary to represent the state of the ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    message:Annotated[list,add_messages] # List of messages, With add_message function applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a StateGraph instance , Specifying the state type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_Builder = StateGraph(State) \n",
    "\n",
    "# Define chatbot function that takes state as input and returns new state with uploaded message\n",
    "def chatbot(State:State):\n",
    "    return {\"message\":[llm.invoke(State[\"message\"])]} # invoke the llm on the input message\n",
    "\n",
    "# Add the chatbot node to the graph , specfying its name and chatbot function\n",
    "graph_Builder.add_node(\"chatbot\",chatbot)\n",
    "\n",
    "# set the chatbot node as both Entry point and finish point\n",
    "graph_Builder.set_entry_point(\"chatbot\")\n",
    "graph_Builder.set_finish_point(\"chatbot\")\n",
    "\n",
    "graph = graph_Builder.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream Graph Based on User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_graph_updates(user_input : str):\n",
    "    #create an initial state with the user input message\n",
    "    Dict = {\"message\":[(\"user\",user_input)]} # creting dictionary having one key which is message and it connects to the tuple two elements 'string' and user_input\n",
    "\n",
    "    #stream updates from the compiled graph\n",
    "    for event in graph.stream(Dict):\n",
    "        #loop through each event value (should be only one in this case)\n",
    "        for value in event.values():\n",
    "            #print the assistant latest message \n",
    "            print(\"Assitant:\",value[\"message\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assitant: Hi! How can I assist you today?\n",
      "Assitant: Hello! How can I assist you today?\n",
      "Assitant: I'm sorry but I do not have the capability to perform this task for you, I am happy to help you with any other queries you may have.\n",
      "Assitant: I'm sorry but I do not have the capability to perform this task for you, I am happy to help you with any other queries you may have.\n",
      "Assitant: I'm sorry but I do not have the capability to perform this task for you, I am happy to help you with any other queries you may have.\n",
      "Good Bye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"user :\") # Get input from the user\n",
    "\n",
    "        if user_input.lower() in [\"quit\",\"q\",\"exit\"]:\n",
    "            print(\"Good Bye!\")\n",
    "            break # Exit the loop\n",
    "\n",
    "        stream_graph_updates(user_input) # process the input using this graph\n",
    "    except Exception as e:\n",
    "        print(\"Exception is Occured during processing :\",e)\n",
    "        stream_graph_updates(user_input)\n",
    "        break # exit the loop after the fallback\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Ram!\n"
     ]
    }
   ],
   "source": [
    "def greet(name):\n",
    "    \"\"\"Function to greet a user.\"\"\"\n",
    "    return f\"Hello, {name}!\"\n",
    "\n",
    "print(greet(\"Ram\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Alice, Age: 25\n",
      "Hobbies: Reading, Traveling\n",
      "Name: Bob, Age: 18\n"
     ]
    }
   ],
   "source": [
    "def display_info(name, age=18, *hobbies):\n",
    "    \"\"\"Display user information.\"\"\"\n",
    "    print(f\"Name: {name}, Age: {age}\")\n",
    "    if hobbies:\n",
    "        print(\"Hobbies:\", \", \".join(hobbies))\n",
    "\n",
    "display_info(\"Alice\", 25, \"Reading\", \"Traveling\")\n",
    "display_info(\"Bob\")  # Uses default age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am local\n"
     ]
    }
   ],
   "source": [
    "def my_function():\n",
    "    local_var = \"I am local\"\n",
    "    return local_var\n",
    "\n",
    "print(my_function())  # Works fine\n",
    "# print(local_var)  # This would raise an error since local_var is not defined outside the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "Error! Division by zero.\n"
     ]
    }
   ],
   "source": [
    "def divide(a, b):\n",
    "    \"\"\"Divide two numbers and return the result.\"\"\"\n",
    "    try:\n",
    "        return a / b\n",
    "    except ZeroDivisionError:\n",
    "        return \"Error! Division by zero.\"\n",
    "\n",
    "print(divide(10, 2))  # Output: 5.0\n",
    "print(divide(10, 0))  # Output: Error! Division by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area of circle: 78.53981633974483\n",
      "Area of rectangle: 24\n"
     ]
    }
   ],
   "source": [
    "def area_circle(radius):\n",
    "    \"\"\"Calculate area of a circle.\"\"\"\n",
    "    import math\n",
    "    return math.pi * radius ** 2\n",
    "\n",
    "def area_rectangle(length, width):\n",
    "    \"\"\"Calculate area of a rectangle.\"\"\"\n",
    "    return length * width\n",
    "\n",
    "print(f\"Area of circle: {area_circle(5)}\")\n",
    "print(f\"Area of rectangle: {area_rectangle(4, 6)}\")  # Output: Area of rectangle: 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
